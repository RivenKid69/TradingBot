Фаза 0 — Каркас модульности (ввод без ломки логики) Цель: Задать базовый каркас слоёв и правил архитектуры, не меняя текущего поведения кода. Шаги: Добавить новые модули и документы архитектуры для разделения интерфейсов и реализаций: core_contracts.py — содержит абстрактные базовые классы (ABC) или Protocol для ключевых компонентов: MarketDataSource, TradeExecutor, FeaturePipe, SignalPolicy, RiskGuards, BacktestEngine (задаёт интерфейсы источника рыночных данных, исполнителя сделок, конвейера фич, стратегий сигналов, блоков риск-менеджмента и движка бэктеста). core_models.py — содержит универсальные структуры данных (например, на основе dataclass или TypedDict): Instrument (торгуемый инструмент), Bar/Tick (рыночный бар/тик), Order (заявка), ExecReport (отчёт об исполнении заявки), Position (позиция) и PortfolioLimits (ограничения портфеля). core_events.py — определяет типы событий (например, классы MarketEvent, OrderEvent, FillEvent) для обмена данными между компонентами через шину событий. core_errors.py — содержит общие классы исключений для типовых ошибок в работе системы. core_config.py — описывает схемы конфигурации (с помощью Pydantic-моделей) для различных режимов работы: обучения (train), симуляции (sim), боевого режима (live) и оценки (eval). di_registry.py — реализует механизм Dependency Injection: фабричную функцию build(component_name, dotted_path), которая через importlib динамически загружает класс по заданному пути и создаёт экземпляр компонента. check_imports.py — добавляет утилиту-линтер на основе AST для проверки соблюдения модульных правил: скрипт анализирует импорты в проекте и запрещает “обратные” импорты вверх по слоям (определяется по префиксам модулей, согласно архитектурным правилам). ARCHITECTURE.md — документ (1 страница) с описанием слоёв архитектуры, допустимых зависимостей между ними (граф зависимостей) и основными правилами кодирования (чтобы каждый разработчик понимал границы между core, impl, service, strategy, scripts и не нарушал их). Обновить существующий код минимально для использования новых контрактов: в некоторых модулях заменить прямые импорты конкретных реализаций на импорт интерфейсов из core_contracts (там, где это можно сделать без масштабного рефакторинга). Например, если раньше модуль напрямую импортировал класс из симулятора или биржевого адаптера, теперь он должен зависеть от соответствующего ABC (контракта). Эти изменения начнут отделять логику от конкретных реализаций, не затрагивая саму функциональность. Критерии готовности: Выполнение скрипта python check_imports.py показывает 0 нарушений архитектурных правил импортов (все зависимости между слоями корректны). Любой существующий сценарий запуска (симуляция, обучение модели и т.д.) работает точно так же, как раньше – поведение системы и результаты не изменились. Фаза 1 — Стабилизация доменной модели Цель: Унитизировать типы основных торговых объектов во всех режимах (симуляция, обучение, онлайн), чтобы использовать единые структуры данных для заявок, исполнений и пр., и тем самым устранить расхождения между симулятором и реальным режимом. Шаги: Унификация типов Order и ExecReport: Просмотреть весь код и привести места создания или чтения ордеров и отчётов об исполнении к новым типам из core_models.py. Например, везде вместо разрозненных структур (словари, namedtuple и т.п.) использовать объекты Order и ExecReport из core_models. Если в симуляторе и в реальном режиме отчёты об исполнении сейчас представлены по-разному, их следует заменить на единый класс ExecReport. Нормализация схем логов: Привести формат логирования торгов и результатов к единому стандарту. Определить в core_models.py структуру вроде TradeLogRow (например, с полями: временная метка, инструмент, сторона (buy/sell), объем, цена, тип ордера, результат исполнения и пр.) и убедиться, что симулятор и реальный режим записывают логи торгов по одной схеме (одинаковые колонки и типы данных). Аналогично, если имеются различия в формате отчётов о доходности/позициях, заложить их единый формат (можно отложить подробный отчёт об equity до фазы 7). Внедрение адаптеров совместимости: Добавить временные прослойки (shim-адаптеры) для поддержки старых структур данных там, где сразу перейти на новые типы сложно. Например, если какие-то функции всё ещё ожидают старый формат ордера или отчёта, реализовать функции-конверторы, которые будут принимать старую структуру и возвращать объект нового Order/ExecReport (или наоборот). Это позволит сохранить обратную совместимость – существующие вызовы не «сломаются» мгновенно, а будут постепенно переведены на новые типы. Критерии готовности: ExecReport используется единообразно: и в режиме симуляции, и при разборе логов (пост-аналитика), теперь применяется один и тот же класс ExecReport из core_models. Нет дублирующихся или конфликтующих классов для представления исполнения ордера. Формат логов торгов унифицирован: скрипты обработки логов, например aggregate_exec_logs.py, успешно работают с нормализованной схемой колонок. Все данные из разных режимов (симуляция или реальные прогоны) агрегируются без дополнительных преобразований, так как формат записей совпадает. Благодаря адаптерам совместимости, существующий код (например, вызовы функций симулятора или анализ логов в обучении) продолжает работать корректно, без ошибок и без изменения своего интерфейса. Фаза 2 — Контракты данных и исполнения Цель: Свести воедино обработку рыночных данных и исполнение ордеров для симулятора и будущего live-режима, предоставив одинаковые «порты» (интерфейсы) для этих компонентов. После этой фазы любая логика выше по уровню сможет работать с унифицированными интерфейсами, не заботясь о том, используется ли под капотом симулятор или реальная биржа. Шаги: Реализация исполнителя торгов (TradeExecutor) на базе симулятора: Создать новый модуль impl_sim_executor.py, в котором оформить класс (например, SimExecutor) реализующий интерфейс TradeExecutor (а при необходимости и BacktestEngine) из core_contracts.py. Этот класс будет выступать прослойкой над существующим механизмом симуляции исполнения заявок. Можно переиспользовать или вызывать существующий код (например, функции из execution_sim.py и/или sim_adapter.py) внутри нового класса, чтобы не переписывать логику с нуля. Задача – инкапсулировать работу симулятора за стандартным интерфейсом TradeExecutor, сохранив все особенности текущего исполнения (квантизация, задержки, логи и т.д.). При этом убедиться, что новый SimExecutor возвращает ExecReport из core_models и обрабатывает Action/Order в формате core_models (см. фазу 1 и 6). Реализация источников рыночных данных (MarketDataSource): Добавить impl_offline_data.py с классом, например OfflineBarSource, реализующим интерфейс MarketDataSource для офлайн-данных. Этот источник будет читать исторические данные (например, из Parquet/CSV файлов с котировками или свечами) и выдавать события MarketEvent потоку стратегий. Можно опираться на существующий функционал агрегации/чтения данных (например, модули agg_klines.py, incremental_klines.py или другие утилиты загрузки исторических данных) – обернуть их в класс, чтобы он скрывал детали чтения и просто генерировал MarketEvent с нужной структурой (например, объект Bar из core_models). Добавить impl_binance_public.py с классом (например, BinancePublicDataSource) тоже реализующим MarketDataSource, но уже для реального времени. Он будет подключаться к публичным потокам данных Binance (через WebSocket/HTTP). По сути, этот класс слушает публичный поток рыночных данных (например, свечи 1m) и преобразует их в события MarketEvent, которые можно подавать в систему. Можно базироваться на коде из binance_public.py и binance_ws.py: внутри нового класса использовать уже реализованные функции запросов REST или подключения к веб-сокету, но предоставить стандартный интерфейс (например, метод .subscribe(symbols) или .get_event() генератор событий и т.п.). Выделение модулей для вспомогательных механизмов исполнения: Перенести и оформить логику квантования цен/количеств, комиссий, проскальзывания, задержки и базовых риск-ограничений в отдельные реализации, чтобы и симулятор, и боевой исполнитель могли использовать их совместно. Создать модули: impl_quantizer.py — содержит функции/классы для квантизации цен и объёмов заявки по биржевым правилам (например, с учётом tick size, lot size, minNotional, и пр.). Эта логика уже присутствует в симуляторе (см. текущий quantizer.py и фильтры из Binance), её нужно выделить в отдельный модуль, сохранив полностью алгоритмы и параметры, чтобы результаты квантования в симе и на бирже совпадали. impl_fees.py — содержит расчёт торговых комиссий (такер/мейкер комиссии, скидки, условия Binance VIP/BNB). Можно перенести функциональность из текущего fees.py. Интерфейс: например, функция apply_fees(order: Order) -> FeeResult или класс FeeModel, используемый исполнителем. impl_slippage.py — рассчитывает проскальзывание цены при исполнении ордеров. В симуляторе эта логика есть (возможно, внутри execution_sim), нужно её экстрагировать. Например, функция apply_slippage(order: Order) -> PriceAdjustment. impl_latency.py — моделирует задержки исполнения и доставки данных. Сейчас задержки управляются параметрами (например, latency_steps), оформляем это как модуль с функциями или классом, чтобы задать единый способ учета задержек (например, метод delay_order(order) или генератор задержанных событий). impl_risk_basic.py — базовые проверки риска и ограничений (например, предотвращение торговли при недостатке средств, лимиты потерь, маски no-trade и т.д.). В проекте уже есть соответствующие части (например, risk.py, risk_guard.py, настройки лимитов в конфиге). Необходимо консолидировать это в одном месте: определить класс или набор функций (например, RiskManager с методами проверки ордера перед исполнением), который использует одинаковые правила как в симуляторе, так и в live-режиме. Новые модули должны содержать чистые функции или независимые классы и не иметь побочных эффектов, чтобы их можно было вызывать из разных исполнителей. В impl_sim_executor.py начать использовать эти новые утилиты: например, при обработке заявки сначала вызывать квантизацию (impl_quantizer), затем рассчитывать комиссию (impl_fees), применять слиппедж (impl_slippage), учитывать задержку (impl_latency) и проверять риски (impl_risk_basic). Таким образом, симулятор начнёт использовать унифицированные компоненты. (Позже, в фазе 8, эти же компоненты будут вызываться и real-time исполнителем ордеров). Критерии готовности: Разработанный сервис бэктеста (см. Фаза 3) способен запускаться и выполнять бэктест, работая исключительно через интерфейсы MarketDataSource и TradeExecutor. То есть, внутри service_backtest мы можем подставить наш OfflineBarSource и SimExecutor, и получить тот же результат бэктеста, что и прежним кодом. Важный признак: код оркестрации бэктеста более не зависит напрямую от конкретных реализаций симулятора или данных — он общается только с интерфейсами и не «знает», реальный это режим или симуляция. Взаимозаменяемость источников данных достигнута: смена источника с офлайн-данных на публичный Binance WS (и обратно) не требует изменений в коде оркестрации. Достаточно подставить другой компонент MarketDataSource, и остальная логика (цикл стратегии, исполнение ордеров) продолжает работать корректно. Это подтверждает, что интерфейсы MarketDataSource/TradeExecutor унифицированы и реализованы правильно. Все новые компоненты (квантизация, комиссии, слиппедж, задержки, риски), вынесенные в отдельные модули, дают идентичный эффект на исполнение ордеров, как и раньше. Симулятор с подключёнными impl_quantizer/fees/... ведёт себя так же, как до рефакторинга (с той лишь разницей, что код стал модульным). Не возникло ситуаций, когда из-за разбиения логики на части меняются результаты исполнения или нарушается какой-то существующий функционал. Фаза 3 — Сервисы (оркестрация сценариев) Цель: Выделить сценарии работы системы (трейдинг, бэктест, обучение, оценка результатов) в отдельные “application service” уровни – тонкие модули-оркестраторы, которые управляют последовательностью вызовов, не содержат бизнес-логики, а только связывают компоненты через их интерфейсы. Это позволит чётко отделить прикладные сценарии от внутренней логики модулей и упростит переключение режимов. Шаги: Создать модули сервисов для основных сценариев: service_signal_runner.py – сервис для онлайн-трейдинга (реального времени). Его задача – запустить цикл обработки данных и сигналов: получать события рынка из MarketDataSource, передавать их в конвейер фич (FeaturePipe), затем в стратегию (SignalPolicy), результаты стратегии пропускать через блоки риск-менеджмента (RiskGuards), и отправлять итоговые торговые решения в исполнитель сделок (TradeExecutor). По сути, это абстракция над текущим signal_runner.py, но без жесткой привязки к конкретным реализациям (Binance WS, конкретной стратегии или симулятору) – все зависимости должны поставляться извне, например, через DI или параметры. service_backtest.py – сервис для бэктестов (офлайн-симуляции). Логика очень похожа на service_signal_runner: те же компоненты (MarketDataSource → FeaturePipe → SignalPolicy → RiskGuards → TradeExecutor), но настроенные на офлайн-режим. Например, MarketDataSource будет OfflineBarSource (чтение исторических данных), а TradeExecutor – наш SimExecutor (из фазы 2). Сервис должен уметь прогнать весь исторический датасет через стратегию и исполнитель, собирая результаты (логи, метрики) аналогично тому, как это делалось раньше в связке симулятора и evaluate_performance. service_train.py – сервис для подготовки данных и обучения модели. Он должен с помощью офлайн-источника данных и FeaturePipe в режиме офлайн собрать датасет признаков и целевых переменных, после чего вызвать обучение модели. По сути, это выделение логики из текущих скриптов обучения (например, train_model_multi_patch.py и др.): чтение исторических данных → генерация фичей (можно переиспользовать FeaturePipe, чтобы не дублировать код преобразований) → сохранение датасета и вызов обучающей процедуры (например, модели RL или супервизорного обучения). В этом сервисе не должно быть самих алгоритмов обучения – они остаются в модулях модели – только последовательность операций. service_eval.py – сервис для оценки результатов торгов/модели. Он отвечает за загрузку логов/результатов прогона и вычисление метрик, построение отчётов. Вынести в него функциональность из текущего evaluate_performance.py и связанных модулей: чтение файлов логов (трейды, equity и т.п.), расчёт метрик эффективности (Sharpe, P&L, drawdown и т.д., часть метрик будет расширена в фазе 7) и формирование итоговых отчетов/графиков. Сервис должен предоставлять методы для получения основных показателей или сохранения их в файлы отчётов. Рефакторинг существующего кода под сервисы: Взять текущую логику из модулей signal_runner.py, evaluate_performance.py, а также из скриптов запусков (например, run_realtime_signaler.py, run_sandbox.py, функции из prepare_and_run.py или других утилит, которые непосредственно запускают сценарии), и переместить эту логику в соответствующие сервисы: только как последовательность вызовов компонентов через их контракты. В каждом сервисе должна быть минимальная “склейка”: например, в service_signal_runner цикл while, который запрашивает MarketDataSource.next_event(), передаёт данные в FeaturePipe.transform(), затем Strategy.decide(), затем RiskGuards.apply(), затем TradeExecutor.execute() — и так по кругу. Никаких деталей конкретной реализации (ни чтения конкретного файла CSV, ни особенностей Binance API, ни подробностей устройства симулятора) внутри сервисов быть не должно, они должны работать с любыми реализациями, удовлетворяющими контрактам. В самом же signal_runner.py и других старых модулях вместо логики оставить тонкие вызовы нового сервиса или полностью удалить их использование, чтобы не было дублирования. Аналогично, evaluate_performance.py либо станет обёрткой вокруг service_eval, либо его функциональность целиком переедет. Критерии готовности: Разработанные скрипты высокого уровня (см. фазу 9) могут запускать необходимые сценарии только через сервисы. В частности, тестовый скрипт для бэктеста (например, script_backtest.py, который будет создан в фазе 9) успешно запускает полный бэктест, вызывая service_backtest и не делая никаких прямых импортов модулей реализаций (таких как execution_sim или offline_data). Это подтверждает, что сервисы инкапсулируют всю необходимую логику. Модуль app.py (если используется интерактивное приложение/дашборд) тоже рефакторится таким образом, что все операции (запуск трейдинга, бэктеста, обучение) происходят через вызовы соответствующих сервисов. app.py больше не лазит напрямую в глубины реализации (не импортирует напрямую feature_pipe или execution_sim и т.п.), а ограничивается вызовом методов сервисов и передачей им параметров. Поведение приложения при этом осталось прежним, но код стал чище и более модульным. Фаза 4 — Фичепайп и паритет офлайн/онлайн Цель: Обеспечить единый путь расчёта признаков (features) из данных как в режиме реального времени, так и при офлайн-обработке исторических данных. Исключить расхождения между логикой подготовки фичей для обучения и для live-трейдинга, добившись их численного соответствия при одинаковом входе. Шаги: Унификация класса конвейера признаков: Привести текущий модуль feature_pipe.py к тому, чтобы он реализовывал интерфейс FeaturePipe из core_contracts.py и умел работать в двух режимах – offline и online. Внутри класса предусмотреть параметр или конфигурацию режима: В offline-режиме – обработка пакетных исторических данных (например, DataFrame с ценами) для подготовки датасета обучения. Здесь можно использовать наработки из текущего класса FeaturePipeline (модуль features_pipeline.py) – перенести или встроить эту функциональность. Возможно, FeaturePipe будет содержать методы вроде fit_transform(historical_data) для обучения преобразований на истории, если это требуется, или просто метод для пакетного расчёта фичей на датасете. В online-режиме – потоковая обработка по одному событию (например, метод transform(event) или on_new_bar(bar)) для вычисления фичей в режиме реального времени, как сейчас делает FeaturePipe для стриминга (он принимает на вход новую 1-минутную свечу и возвращает словарь фичей). Реализовать единый метод инициализации/прогрева (warmup()), который подготавливает необходимые структуры (например, очереди значений для скользящих окон, последние значения индикаторов, учёт часовых поясов, заполнение пропущенных данных и т.п.) и в офлайне, и в онлайне. Таким образом, FeaturePipe станет единым классом, способным и обучать трансформеры на истории, и применять их в реальном времени. Интеграция трансформеров признаков через композицию: Убедиться, что все существующие преобразования признаков (индикаторы, статистики и т.д., которые сейчас разбросаны, возможно, между transformers.py, featuresbasic.py, features_pipeline.py и самим FeaturePipe) подключены к новому FeaturePipe через композицию или делегацию. Например, если есть модуль transformers.py с классами или функциями для расчёта конкретных фичей (скользящих средних, волатильности, и пр.), то внутри FeaturePipe можно держать список таких трансформеров или pipeline, последовательно применяя их к входящим данным. Цель – избежать дублирования кода между offline и online: все преобразования определяются в одном месте и применяются одинаково в обоих режимах. Если были отдельные реализации для обучения и боевого режима, объединить их. Добавить утилиту проверки паритета фичей: Создать скрипт script_parity_check.py, который будет служить инструментом для разработчиков с целью сравнить выход конвейера признаков в офлайн- и онлайн-режиме. Работа скрипта: он берёт некоторую фиксированную последовательность рыночных событий (например, серию баров за день) и прогоняет её через FeaturePipe в offline-режиме (пакетно) и через тот же FeaturePipe в online-режиме (эмулируя поступление баров последовательно). Затем сравнивает полученные последовательности фичей и выводит расхождения по каждому временному шагу. Это не автоматический тест, а вспомогательный инструмент: допустим, скрипт печатает на консоль метрики расхождения или первые N случаев несовпадения. Разработчики смогут по этому отчёту убедиться, что конвейер фичей работает консистентно. Критерии готовности: Для одной и той же последовательности входных данных (например, тех же котировок), рассчитанные в офлайне и онлайне признаки совпадают с точностью до допустимой погрешности. В ARCHITECTURE.md следует зафиксировать критерий: расхождение признаков на идентичном входе ≤ ε, где ε – некий малый допуск из-за возможных нюансов вычислений с плавающей точностью. Если script_parity_check.py выявляет расхождение выше эпсилон, это означает несовершенную унификацию и должно быть исправлено. В идеале же, для всех ключевых фичей результаты должны быть бит-в-бит одинаковы. Конвейер признаков стал модульным и единым: нет раздвоения кода на «онлайн-FeaturePipe» и «офлайн-FeaturePipeline». Все трансформеры и логика расчёта признаков определены в одном месте. При переходе из режима backtest (исторический прогон) в режим live не требуется переписывать или дублировать код признаков – используется один и тот же FeaturePipe, просто сконфигурированный на другой источник данных. Обработка специальных случаев, таких как пропуски данных или несовпадение таймзон, выполняется одинаково в обоих режимах. Нет ситуации, когда в офлайне данные очищаются иначе, чем в онлайне, – все эти правила теперь централизованы в FeaturePipe. Таким образом, качество и состав фичей, подаваемых на стратегию, не зависит от режима работы системы. Фаза 5 — Конфиги и DI Цель: Добиться, чтобы переключение между разными режимами и компонентами (симуляция ↔ live, разные источники данных, параметры стратегии и риска) осуществлялось изменением конфигурационных файлов, без изменений кода. Внедрить централизованный механизм загрузки конфигов и создания компонентов через DI, чтобы сборка системы была декларативной. Шаги: Создать единые YAML-конфиги для разных сценариев: Добавить файлы конфигурации верхнего уровня, например: config_sim.yaml (для симуляций и бэктестов), config_live.yaml (для боевого режима на бирже), config_train.yaml (для обучения модели) и config_eval.yaml (для оценки метрик/отчётов). Эти конфиги должны охватывать все основные параметры запуска. В них завести секцию, например, components, где перечислить используемые реализации компонентов: components: market_data: "impl_offline_data:OfflineBarSource" executor: "impl_sim_executor:SimExecutor" feature_pipe: "feature_pipe:FeaturePipe" strategy: "strategies.momentum:MomentumStrategy" risk_guards: "impl_risk_basic:BasicRiskManager" # ... и т.д. для всех важных компонентов Здесь каждый компонент указывает dotted path до класса (или функции) его реализации. В конфиг также включить необходимые гиперпараметры и настройки: например, параметры комиссий и ликвидности, ограничения риска (такие как дневной лимит потерь, размер лота и прочее), настройки модели/стратегии (пороговые значения, индикаторы) и т.д. Для live-конфига config_live.yaml – свои значения (например, ключи API, флаги использования реальных денег/теста, параметры перезапуска при разрыве соединения). Для train – параметры обучения (размеры трен/тест выборок, гиперпараметры модели), для eval – пути к логам и выбранные метрики. Поддержка новых конфигов в core_config и DI: В модуле core_config.py описать Pydantic-модели, соответствующие структуре YAML. Например, класс SimulationConfig с полями для каждого раздела (components, fees, limits, etc.), LiveConfig, TrainConfig, EvalConfig. Эти модели помогут валидировать конфиг и обеспечить доступ к параметрам через объект, а не через словарь. Доработать di_registry.py, чтобы он умел по загруженному конфиг-объекту собрать необходимые экземпляры классов: пройтись по секции components, для каждого компонента через importlib импортировать указанный класс и вызвать его конструктор. При этом можно передавать в конструкторы параметры из конфигурации (например, для стратегии – её параметры, для risk_guard – лимиты и т.д.). То есть, di_registry должен построить весь граф объектов приложения, разрешая зависимости. Например, если стратегия требует доступ к какому-то компоненту при инициализации, DI должен это учесть (возможно, через передачу тех же config или зависимостей явно). Автоматизация сохранения и переключения конфигураций: Обеспечить удобство использования конфигов: например, в сервисах или скриптах запусков сделать так, чтобы при старте указывался путь до нужного YAML (--config=config_sim.yaml), загружался соответствующий Pydantic-объект и прокидывался в di_registry для сборки. Реализовать сохранение снэпшота конфигурации каждого прогона: при старте сохранать копию используемого конфиг-файла (или финального объекта) в артефакты, например, artifact_config_<runid>.yaml, чтобы всегда можно было посмотреть, с какими настройками был произведён данный запуск. Это важно для воспроизводимости экспериментов. Критерии готовности: Переключение режима с симулятора на боевой режим (и обратно) выполняется простой заменой конфигурационного файла, без каких-либо изменений в коде приложений. Например, если раньше, чтобы перейти на Binance, нужно было импортировать другие классы или менять логику, теперь достаточно запустить сервис/скрипт с config_live.yaml вместо config_sim.yaml. DI сам подтянет нужные реализации (Binance WS, реальный исполнитель ордеров и т.п.). Все ключевые параметры стратегии и инфраструктуры управляются через конфиг. Для тюнинга или эксперимента не требуется заходить в код – достаточно отредактировать YAML. При этом все ранее доступные возможности настройки сохранились: новый механизм конфигов не урезает функциональность, а лишь централизует её. При запуске любого сценария создаётся копия конфигурации в виде артефакта. Повторный запуск с тем же конфигом даёт идентичные результаты (с учётом детерминизма симуляции, если задан seed) – это подтверждает, что конфиг полностью описывает поведение системы. Фаза 6 — Стратегии и действия Цель: Очистить стратегический слой от деталей инфраструктуры, обеспечить чёткое разделение между стратегией (правила принятия решений) и окружающей средой (данные, исполнение, риски). Ввести строгие типы для торговых решений (действий), чтобы исключить двусмысленность и упростить последующую обработку сигналов. Шаги: Приведение стратегий к интерфейсу SignalPolicy: Ввести в core_contracts.py абстрактный интерфейс SignalPolicy (если не сделано в фазе 0) с методами, необходимыми для работы стратегии – например, setup(config), on_features(features: Dict), decide(context) -> List[Action]. К этому интерфейсу адаптировать существующую базовую стратегию. В частности, класс BaseStrategy из base.py должен реализовывать SignalPolicy: проверить, что его методы (инициализация setup, получение новых фичей, принятие решения decide) соответствуют требуемой сигнатуре. Если нет – скорректировать их. Например, можно сделать BaseStrategy.decide() возвращающим список действий стандартизированного типа (см. ниже), а не кастомный объект Decision. Введение строгих типов Action и OrderIntent: В core_models.py определить четкие структуры для выхода стратегии. Например, ввести класс Action (или переработать существующий ActionProto из action_proto.py) как dataclass с полями: тип действия (enum: BUY, SELL, HOLD, CANCEL и т.п. – возможно, использовать/расширить имеющийся ActionType), параметр цены (для лимитных ордеров, например, оффсет или абсолютная цена), желаемый объем (в долях от позиции или абсолютное количество) и, возможно, признак инструмента/тикера, если стратегия может работать с несколькими инструментами. Также можно ввести понятие OrderIntent – может быть, синоним или расширение Action, описывающее конкретное намерение выставить ордер (уже более привязанное к конкретному инструменту и портфелю). Цель – заменить разрозненные представления сигналов: сейчас есть класс Decision (в base.py) с полями side/volume_frac, есть ActionProto (в action_proto.py) с action_type/volume_frac/price_offset. Нужно прийти к одному стандарту. Например, можно использовать ActionProto как основу, дополнив недостающими атрибутами (или просто переименовать его в Action), а Decision убрать или преобразовать в совместимый вид. После введения новых типов, обновить стратегический код на их использование: BaseStrategy.decide пусть формирует список Action вместо списка Decision. Внутренне стратегия может продолжать использовать упрощённую логику (например, брать side и объем), но на выходе она упаковывает это в Action. Добавить при необходимости адаптеры, чтобы старые стратегии (если они возвращают старый формат) всё ещё работали – например, обернуть их результат в Action. Разделение стратегий по файлам и зависимостям: Если в проекте разные стратегии сейчас определены в одном модуле или вместе с инфраструктурным кодом, разнести их. Создать отдельные файлы для стратегий, например, strategy_example.py, strategy_momentum.py, strategy_xyz.py (можно переименовать существующие momentum.py и пр. под эту схему). Каждая стратегия должна импортировать только core-модули – т.е. она может использовать core_models (типы ордеров, позиции и т.д.), core_contracts (интерфейсы, если нужно для типов), core_events (если стратегия реагирует на события), и, конечно, стандартную библиотеку/научные пакеты. Никаких импортов реализаций (ни симулятора, ни конкретных данных, ни executor’ов) внутри стратегий быть не должно. Стратегия должна быть полностью отвязана от деталей – она получает на вход уже готовые рассчитанные фичи (словари чисел) и возвращает торговые сигналы. Благодаря этому одну и ту же стратегию можно будет запускать и на исторических данных, и в реальном времени, не меняя её код. Перенос инфраструктурных элементов из стратегии: Проверить, не выполняет ли сейчас стратегический код задачи, несвойственные стратегии. Например, применение масок “no-trade” (не торговать в определённых ситуациях) или проверка режима рынка. Если такие логики присутствуют внутри стратегий (или в базовом классе Decision), их нужно вынести либо в слой риска (например, в impl_risk_basic как отдельные проверки), либо оформить как часть конвейера фичей (если это трансформация данных, напр. пометка баров, когда торговать нельзя). Цель – стратегия должна концентрироваться только на своем алгоритме торговли. Так, модуль no_trade.py и подобные ему конфигурации должны применяться не в стратегии, а до неё (например, RiskGuards могут просто аннулировать сигнал, если сейчас “окно запрета торговли”). Критерии готовности: Все стратегии в кодовой базе теперь соответствуют единому интерфейсу SignalPolicy. Любую конкретную стратегию (моментум, контртренд, и т.д.) можно запустить через общую точку вызова – например, передав её класс в конфиг и вызвав service_signal_runner, без дополнительного кода, специфичного для этой стратегии. Стратегии стали взаимозаменяемыми с точки зрения остальной системы. Формат действий стратегии стандартизирован: вместо произвольных структур или “пар важных чисел” на выходе, теперь везде используются объекты Action (и/или OrderIntent) из core_models. Это значит, что downstream-компоненты (исполнитель, симулятор) принимают на вход понятный объект с явными полями, а не, скажем, список [0.5, 1]. Весь код, где ранее разбирались детали решения стратегии, переписан на работу с новым типом (включая симулятор, калибровщик, risk-менеджер и пр.). При этом адаптация проведена без потери функциональности: например, если ранее Decision.side определял BUY/SELL, теперь это также однозначно определяется через Action.action_type и знак/поле объёма. Никакая информация не утеряна, а трактовка сигналов только упростилась. Стратегический код не содержит “побочных” зависимостей: при изучении модулей стратегий видно, что они не зависят от конкретных реализаций системы. Таким образом, стратегию можно разрабатывать и тестировать в отрыве от всей инфраструктуры (например, заглушив интерфейсы). Это подтверждается тем, что check_imports.py не находит запрещённых импортов (стратегии импортируют только core/*). Все инфраструктурные детали (тайминги торгов, фильтры, маски, риски) обрабатываются вне стратегии. Фаза 7 — Логи, метрики, отчёты Цель: Ввести единый формат логирования и минимально необходимый набор метрик для оценки работы стратегии, чтобы каждая попытка или запуск алгоритма давали сопоставимые результаты без дополнительной ручной обработки. Закрепить структуру отчётности и метрик на уровне архитектуры. Шаги: Стандартизация форматов логов и отчётов: Определить и зафиксировать в архитектуре формат файлов логов трейдов и отчётов о результатах. В документации (ARCHITECTURE.md) описать схемы файлов: log_trades_<runid>.csv – построчный лог исполненных сделок/ордеров. Например, колонки: timestamp, instrument, side, price, quantity, order_type, fee, pnl, etc., а также, возможно, идентификатор запуска или стратегии. Эта схема должна соответствовать тому, что было заложено в core_models.TradeLogRow на фазе 1 (при необходимости доработать её). report_equity_<runid>.csv – временной ряд значений equity/баланса портфеля на каждом шаге или конце дня и т.п. Колонки: timestamp, equity, drawdown, etc. Возможно, дублировать в report_equity_<runid>.json для удобства (или строить графики прямо в коде). Убедиться, что при выполнении бэктеста или live-трейдинга эти логи и отчёты формируются автоматически сервисами (из фазы 3) в указанном формате, без необходимости вручную конвертировать или копировать данные. Если в текущем коде часть этой информации выводится на экран или сохраняется в другом виде, переписать на запись в стандартизированные файлы. Все схемы и типы для записей логов/отчётов описать в core_models.py (например, dataclass TradeLogRow, EquityPoint и т.д.), чтобы обеспечить типобезопасность при работе с ними в коде (например, сервис оценки будет оперировать списком таких объектов или DataFrame с заданными колонками). Интеграция метрик в сервис оценки: Перенести или реализовать расчёт ключевых метрик в модуле metrics.py (или внутри service_eval.py) так, чтобы по данным логов можно было получить единообразный набор показателей эффективности стратегии. Расширить текущий набор метрик, если он ограничен: добавить расчёт Sharpe ratio, Sortino ratio, Calmar ratio, максимальной просадки (Max Drawdown, MDD), turnover (оборот портфеля), hit-rate (процент прибыльных сделок), CVaR (Conditional Value at Risk) и других важных показателей, если их не хватает. Многие из этих метрик, возможно, уже присутствуют в metrics.py или evaluate_performance.py – нужно убедиться, что они правильно вычисляются на основе стандартизированных логов. Свести подсчёт метрик в одном месте: например, сделать функцию calculate_metrics(trade_log: DataFrame, equity_curve: DataFrame) -> Dict[str, float], которую будет вызывать сервис оценки. Таким образом, отключаем “разрозненные” подсчёты – вместо того, чтобы вычислять Sharpe в одном скрипте, а MDD в другом, все ключевые показатели считаются вместе. Скрипт сравнения результатов нескольких запусков: Добавить script_compare_runs.py, который позволит проанализировать несколько прогонов стратегии. Его функция – брать артефакты (логи/отчёты) от разных запусков и выводить сравнительную таблицу метрик. Например, на вход скрипту даётся список папок или файлов разных экспериментов, он загружает их отчёты и печатает таблицу: RunID, Sharpe, Sortino, MDD, PnL, Hit-rate и т.п. Это поможет быстро оценивать изменения между версиями стратегии или параметров. Реализовать скрипт максимально просто (парсит конфиг или принимает пути через аргументы командной строки, и использует функции из service_eval/metrics для извлечения показателей). Критерии готовности: После каждого прогона (не важно, симуляция это или реальный запуск), в папке логов появляются структурированные файлы log_trades_*.csv и report_equity_*.csv с данными о сделках и результатах. Эти файлы имеют одинаковую структуру между запусками и между разными режимами работы. Например, больше нет ситуации, что для симулятора лог имел одни колонки, а для live – другие: все сценарии пишут логи по одной схеме. Сервис оценки (eval) без дополнительной ручной работы выдаёт итоговый отчёт по каждому запуску. То есть, запустив service_eval (например, через скрипт script_eval.py) на указанный лог, пользователь сразу получает расчет всех основных метрик и сформированный отчёт (в консоли, файле или UI) – никаких ручных вычислений в Jupyter после этого не требуется. Формулы метрик проверены, и они соответствуют отраслевым стандартам (расчёт на годовую волатильность для Sharpe и т.д.). Инструменты калибровки и сравнения работают на новых форматах: например, aggregate_exec_logs.py (перенесённый, если нужен) и новый script_compare_runs.py успешно обрабатывают несколько файлов логов, подтверждая, что все необходимые данные присутствуют и сопоставимы. Минимальный набор метрик позволяет сравнить эффективность разных запусков “одним взглядом”. При этом лишние или избыточные метрики, которые раньше могли расчитываться, убраны или вынесены из основных отчетов, чтобы не загромождать анализ – оставлены только ключевые (но пользователь всё ещё может подробнее копнуть лог при желании, формат открытый). Фаза 8 — CLI-скрипты запуска сценариев Цель: Предоставить чистые точки входа для каждого сценария использования (обучение, бэктест, запуск стратегии live, калибровка параметров), чтобы пользователи или разработчики могли запускать их одной командой, без необходимости заходить внутрь кода. Все сложные детали уже инкапсулированы в сервисах и конфигурациях, скрипты же просто связывают конфиг и соответствующий сервис. Шаги: Создать набор скриптов для запуска: Для каждого основного сценария написать небольшой Python-скрипт в корне проекта: script_train.py – парсит аргументы (например, путь до конфигурации обучения config_train.yaml), загружает конфиг, затем вызывает соответствующие функции из service_train для подготовки данных и обучения модели. В конце может сохранять обученную модель или статистику. Весь основной процесс обучения проходит внутри сервисов/моделей; скрипт только соединяет конфиг с вызовом. script_backtest.py – аналогично, принимает конфиг бэктеста (например, config_sim.yaml или отдельный config_backtest.yaml), создает через DI необходимые компоненты (OfflineBarSource, SimExecutor, стратегию и т.д.) и запускает service_backtest на указанном историческом периоде. По завершении информирует, где лежат логи/отчёты. script_eval.py – принимает на вход конфиг оценки (config_eval.yaml, где прописаны пути к логам/результатам конкретного прогона), либо напрямую пути к файлам логов, запускает service_eval и выводит/сохраняет метрики и отчёт. script_live.py – запускает стратегию в боевом режиме. Принимает конфиг live (config_live.yaml), поднимает через DI компоненты (BinanceTradeExecutor, BinanceMarketDataSource и прочие) и передаёт их в service_signal_runner для старта цикла. Также может обрабатывать сигналы завершения (например, по Ctrl+C корректно завершать работу, закрывать подключения). script_calibrate_tcost.py – сценарий калибровки транзакционных издержек. Если в системе предусмотрено автоматическое определение параметров слиппеджей/комиссий (например, на основе данных рынка), этот скрипт грузит нужные данные, вызывает функции, возможно, из service_train или отдельного модуля калибровки, и сохраняет откорректированные параметры (например, в конфиг или отдельный файл). Ранее были скрипты calibrate_tcost.py и calibrate_slippage.py – их логику можно перенести сюда, привязав к новым компонентам. script_calibrate_slippage.py – аналогично выше, только для слиппеджа. Минимализм логики в скриптах: Убедиться, что каждый из этих скриптов выполняет только следующие простые шаги: парсинг аргументов (можно с помощью argparse/typer), загрузка YAML-конфига (если применимо), и вызов одного метода сервиса. Никакой бизнес-логики (никаких вычислений метрик, ручного чтения файлов, сложных циклов) внутри скриптов быть не должно – всё это уже реализовано внутри соответствующих сервисов и модулей. Например, script_backtest.py не должен сам по шагам прогонять историю – он просто вызывает service_backtest.run(config) и ждёт окончания. Это гарантирует, что улучшения в логике (в сервисах) автоматически отражаются на поведении скриптов, и что скрипты остаются тонкими и лёгкими в поддержке. Критерии готовности: Любой сценарий работы системы запускается одной командой с указанием соответствующего конфигурационного файла, без необходимости менять код. Например: python script_train.py --config=config_train.yaml, python script_backtest.py --config=config_sim.yaml и т.д. Этот запуск выполняет весь процесс целиком (до сохранения модели или логов) автономно. Пользователь больше не должен руками вызывать последовательность функций из разных модулей – достаточно запустить скрипт. Во всех этих точках входа отсутствует дублирование кода между собой и с основными модулями. Если, к примеру, логика бэктеста меняется, правки делаются в service_backtest.py, и скрипт script_backtest.py автоматически начинает работать по-новому, без его изменения. Это достигается тем, что скрипты доверяют сервисам всю работу. Структура проекта окончательно отражает модульность: слои core, impl, services, strategies, scripts четко разделены, и ни один из CLI-скриптов не лезет вниз по слоям. Проверка check_imports.py подтверждает, что скрипты импортируют только сервисы (и, возможно, core для чтения конфигов), сервисы импортируют только core и impl, а impl не тянет за собой ничего сверху. Все ранее реализованные возможности системы сохранились, но теперь ими проще пользоваться и поддерживать их.